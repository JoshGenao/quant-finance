{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on Quantopian\n",
    "\n",
    "## Overview\n",
    "1. Define trading universe to use ([Q500US and Q1500US](https://www.quantopian.com/posts/the-q500us-and-q1500us)).\n",
    "2. Define alphas (implemented in [Pipeline](https://www.quantopian.com/tutorials/pipeline)).\n",
    "3. Run pipeline.\n",
    "4. Split into train and test set.\n",
    "5. Preprocess data (rank alphas, subsample, align alphas with future returns, impute, scale).\n",
    "6. Train Machine Learning classifier ([Random Forest from Scikit-Learn](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)).\n",
    "7. Evaluate Machine Learning classifier on test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.pipeline.factors import Latest\n",
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline.data import morningstar\n",
    "from quantopian.pipeline.factors import CustomFactor, DailyReturns, SimpleMovingAverage, EWMA, AverageDollarVolume, Returns, RSI, VWAP\n",
    "from quantopian.pipeline.classifiers.morningstar import Sector\n",
    "from quantopian.pipeline.filters import Q500US, Q1500US\n",
    "from quantopian.pipeline.data.quandl import fred_usdontd156n as libor\n",
    "from quantopian.pipeline.data.morningstar import Fundamentals\n",
    "\n",
    "import talib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import math  \n",
    "\n",
    "import alphalens as al\n",
    "import pyfolio as pf\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import grid_search, linear_model, decomposition, ensemble, preprocessing, isotonic, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of some commonly used factors\n",
    "The factors below are a small collection of commonly used alphas that were coded by Gil Wassermann. I will post a separate Notebook with the full collection and more descriptions of them. Ultimately we will put these into a library you can just import to avoid the wall of text. If you want to understand more about pipeline, read the [tutorial](https://www.quantopian.com/tutorials/pipeline).\n",
    "\n",
    "Also note the `Earnings_Quality` alpha which uses [Zacks Earnings Surprises](https://www.quantopian.com/data/zacks/earnings_surprises), a [new source from our partners](https://www.quantopian.com/data).\n",
    "\n",
    "The details of these factors are not the focus of this Notebook so feel free to just [skip](#universe) this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = morningstar.balance_sheet\n",
    "cfs = morningstar.cash_flow_statement\n",
    "is_ = morningstar.income_statement\n",
    "or_ = morningstar.operation_ratios\n",
    "er = morningstar.earnings_report\n",
    "v = morningstar.valuation\n",
    "vr = morningstar.valuation_ratios\n",
    "\n",
    "def make_factors():\n",
    "    \n",
    "    class APR(CustomFactor):  \n",
    "        inputs = [USEquityPricing.close,USEquityPricing.high,USEquityPricing.low]  \n",
    "        window_length = 252  \n",
    "        def compute(self, today, assets, out, close, high, low):  \n",
    "            hml = high - low  \n",
    "            hmpc = np.abs(high - np.roll(close, 1, axis=0))  \n",
    "            lmpc = np.abs(low - np.roll(close, 1, axis=0))  \n",
    "            tr = np.maximum(hml, np.maximum(hmpc, lmpc))  \n",
    "            atr = np.mean(tr[1:], axis=0) #skip the first one as it will be NaN  \n",
    "            apr = atr / close[-1]  \n",
    "            out[:] = apr  \n",
    "        \n",
    "    def Asset_Growth_3M():\n",
    "        return Returns(inputs=[bs.total_assets], window_length=63)\n",
    "\n",
    "    def Asset_To_Equity_Ratio():\n",
    "        return bs.total_assets.latest / bs.common_stock_equity.latest\n",
    "\n",
    "    def Capex_To_Cashflows():\n",
    "        return (cfs.capital_expenditure.latest * 4.) / \\\n",
    "            (cfs.free_cash_flow.latest * 4.)\n",
    "    \n",
    "    class Downside_Volatility(CustomFactor):  \n",
    "        inputs = [DailyReturns()]  \n",
    "        window_length = 126  \n",
    "        def compute(self, today, assets, out, returns):  \n",
    "            returns[returns > 0] = np.nan  \n",
    "            down_vol = np.nanstd(returns, axis = 0)  \n",
    "            ann_down_vol = down_vol*math.sqrt(252)  \n",
    "            out[:] = ann_down_vol\n",
    "        \n",
    "    def EBITDA_Yield():\n",
    "        return (is_.ebitda.latest * 4.) / \\\n",
    "            USEquityPricing.close.latest        \n",
    "\n",
    "    def EBIT_To_Assets():\n",
    "        return (is_.ebit.latest * 4.) / \\\n",
    "            bs.total_assets.latest\n",
    "    \"\"\"\n",
    "    def Earnings_Quality():\n",
    "        return morningstar.cash_flow_statement.operating_cash_flow.latest / \\\n",
    "               EarningsSurprises.eps_act.latest\n",
    "      \n",
    "    \n",
    "    class Fourier_Extrapolation(CustomFactor):\n",
    "        inputs = [DailyReturns(window_length=80)] \n",
    "        window_length = 252\n",
    "        \n",
    "        def compute(self, today, assets, out, rets):\n",
    "            n = rets.size\n",
    "            n_predict = 10\n",
    "            n_harm = 20                     # number of harmonics in model\n",
    "            t = np.arange(0, n)\n",
    "            try:            \n",
    "                p = np.polyfit(t, rets, 1)         # find linear trend in x\n",
    "                x_notrend = rets - p[0] * t        # detrended x\n",
    "                x_freqdom = np.fft.fft(x_notrend)  # detrended x in frequency domain\n",
    "                f = np.fft.fftfreq(n)              # frequencies\n",
    "                indexes = list(range(n))\n",
    "                # sort indexes by frequency, lower -> higher\n",
    "                indexes.sort(key = lambda i: np.absolute(f[i]))\n",
    "\n",
    "                t = np.arange(0, n + n_predict)\n",
    "                restored_sig = np.zeros(t.size)\n",
    "                for i in indexes[:1 + n_harm * 2]:\n",
    "                    ampli = np.absolute(x_freqdom[i]) / n   # amplitude\n",
    "                    phase = np.angle(x_freqdom[i])          # phase\n",
    "                    restored_sig += ampli * np.cos(2 * np.pi * f[i] * t + phase)\n",
    "\n",
    "                extrapolation = restored_sig + p[0] * t \n",
    "                out[:] = (1+extrapolation[-n_predict:]).cumprod()-1\n",
    "            except:\n",
    "                out[:] = np.nan\n",
    "    \"\"\"\n",
    "    def Return_On_Total_Invest_Capital():\n",
    "        return or_.roic.latest\n",
    "    \n",
    "    def Market_Cap():\n",
    "        return v.market_cap.latest\n",
    "    \n",
    "    class Mean_Reversion_1M(CustomFactor):\n",
    "        inputs = [Returns(window_length=21)]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, monthly_rets):\n",
    "            out[:] = (monthly_rets[-1] - np.nanmean(monthly_rets, axis=0)) / \\\n",
    "                np.nanstd(monthly_rets, axis=0)\n",
    "                \n",
    "    class MACD_Signal_10d(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 60\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "\n",
    "            sig_lines = []\n",
    "\n",
    "            for col in close.T:\n",
    "                # get signal line only\n",
    "                try:\n",
    "                    _, signal_line, _ = talib.MACD(col, fastperiod=12,\n",
    "                                                   slowperiod=26, signalperiod=10)\n",
    "                    sig_lines.append(signal_line[-1])\n",
    "                # if error calculating, return NaN\n",
    "                except:\n",
    "                    sig_lines.append(np.nan)\n",
    "            out[:] = sig_lines \n",
    "    \n",
    "    class Moneyflow_Volume_5d(CustomFactor):\n",
    "        inputs = [USEquityPricing.close, USEquityPricing.volume]\n",
    "        window_length = 5\n",
    "\n",
    "        def compute(self, today, assets, out, close, volume):\n",
    "\n",
    "            mfvs = []\n",
    "\n",
    "            for col_c, col_v in zip(close.T, volume.T):\n",
    "\n",
    "                # denominator\n",
    "                denominator = np.dot(col_c, col_v)\n",
    "\n",
    "                # numerator\n",
    "                numerator = 0.\n",
    "                for n, price in enumerate(col_c.tolist()):\n",
    "                    if price > col_c[n - 1]:\n",
    "                        numerator += price * col_v[n]\n",
    "                    else:\n",
    "                        numerator -= price * col_v[n]\n",
    "\n",
    "                mfvs.append(numerator / denominator)\n",
    "            out[:] = mfvs      \n",
    "           \n",
    "    def Net_Income_Margin():\n",
    "        return or_.net_margin.latest           \n",
    "\n",
    "    def Operating_Cashflows_To_Assets():\n",
    "        return (cfs.operating_cash_flow.latest * 4.) / \\\n",
    "            bs.total_assets.latest\n",
    "\n",
    "    def Price_Momentum_3M():\n",
    "        return Returns(window_length=63)\n",
    "    \n",
    "    class Price_Oscillator(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            four_week_period = close[-20:]\n",
    "            out[:] = (np.nanmean(four_week_period, axis=0) /\n",
    "                      np.nanmean(close, axis=0)) - 1.\n",
    "    \n",
    "    def Returns_39W():\n",
    "        return Returns(window_length=215)\n",
    "    \n",
    "    class Trendline(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        # using MLE for speed\n",
    "        def compute(self, today, assets, out, close):\n",
    "\n",
    "            # prepare X matrix (x_is - x_bar)\n",
    "            X = range(self.window_length)\n",
    "            X_bar = np.nanmean(X)\n",
    "            X_vector = X - X_bar\n",
    "            X_matrix = np.tile(X_vector, (len(close.T), 1)).T\n",
    "\n",
    "            # prepare Y matrix (y_is - y_bar)\n",
    "            Y_bar = np.nanmean(close, axis=0)\n",
    "            Y_bars = np.tile(Y_bar, (self.window_length, 1))\n",
    "            Y_matrix = close - Y_bars\n",
    "\n",
    "            # prepare variance of X\n",
    "            X_var = np.nanvar(X)\n",
    "\n",
    "            # multiply X matrix an Y matrix and sum (dot product)\n",
    "            # then divide by variance of X\n",
    "            # this gives the MLE of Beta\n",
    "            out[:] = (np.sum((X_matrix * Y_matrix), axis=0) / X_var) / \\\n",
    "                (self.window_length)\n",
    "        \n",
    "    class Vol_3M(CustomFactor):\n",
    "        inputs = [Returns(window_length=2)]\n",
    "        window_length = 63\n",
    "\n",
    "        def compute(self, today, assets, out, rets):\n",
    "            out[:] = np.nanstd(rets, axis=0)\n",
    "            \n",
    "    def Working_Capital_To_Assets():\n",
    "        return bs.working_capital.latest / bs.total_assets.latest\n",
    "    \n",
    "    class CCI(CustomFactor):\n",
    "        inputs = [USEquityPricing.high, USEquityPricing.low, USEquityPricing.close]\n",
    "        window_length = 20\n",
    "        \n",
    "        def compute(self, today, assets, out, high, low, close):\n",
    "            anynan = np.isnan(high).any(axis=0)\n",
    "        \n",
    "            # In general, it's a bad practice to iterate over numpy arrays like this in pure\n",
    "            # python. Unfortunately, TALib doesn't provide us with an API to vectorize\n",
    "            # operations over 2D arrays, so we're stuck with doing this.\n",
    "            # A nice improvement to Zipline would be to provide a module that does this \n",
    "            # efficiently in Cython.\n",
    "            for col_ix, have_nans in enumerate(anynan):\n",
    "\n",
    "                # If we have nans in the input (e.g., because an asset didn't trade for a \n",
    "                # full day, or because the asset hasn't existed for 14 days), just forward\n",
    "                # the NaN.\n",
    "                if have_nans:\n",
    "                    out[col_ix] = np.nan\n",
    "                    continue\n",
    "                    \n",
    "                results = talib.CCI(\n",
    "                    high[:, col_ix], \n",
    "                    low[:, col_ix], \n",
    "                    close[:, col_ix],\n",
    "                    self.window_length)\n",
    "                \n",
    "                out[col_ix] = results[-1]\n",
    "            \n",
    "    class MFI(CustomFactor):  \n",
    "        \"\"\"  \n",
    "        Money Flow Index  \n",
    "        Volume Indicator  \n",
    "        **Default Inputs:**  USEquityPricing.high, USEquityPricing.low, USEquityPricing.close, USEquityPricing.volume  \n",
    "        **Default Window Length:** 15 (14 + 1-day for difference in prices)  \n",
    "        http://www.fmlabs.com/reference/default.htm?url=MoneyFlowIndex.htm  \n",
    "        \"\"\"     \n",
    "\n",
    "        inputs = [USEquityPricing.high, USEquityPricing.low, USEquityPricing.close, USEquityPricing.volume]  \n",
    "        window_length = 15\n",
    "\n",
    "        def compute(self, today, assets, out, high, low, close, vol):\n",
    "\n",
    "            # calculate typical price  \n",
    "            typical_price = (high + low + close) / 3.\n",
    "\n",
    "            # calculate money flow of typical price  \n",
    "            money_flow = typical_price * vol\n",
    "\n",
    "            # get differences in daily typical prices  \n",
    "            tprice_diff = (typical_price - np.roll(typical_price, 1, axis=0))[1:]\n",
    "\n",
    "            # create masked arrays for positive and negative money flow  \n",
    "            pos_money_flow = np.ma.masked_array(money_flow[1:], tprice_diff < 0, fill_value = 0.)  \n",
    "            neg_money_flow = np.ma.masked_array(money_flow[1:], tprice_diff > 0, fill_value = 0.)\n",
    "\n",
    "            # calculate money ratio  \n",
    "            money_ratio = np.sum(pos_money_flow, axis=0) / np.sum(neg_money_flow, axis=0)\n",
    "\n",
    "            # MFI  \n",
    "            out[:] = 100. - (100. / (1. + money_ratio))  \n",
    "        \n",
    "    all_factors = {\n",
    "        'APR_ratio': APR,\n",
    "        'Asset Growth 3M': Asset_Growth_3M,\n",
    "        'Asset to Equity Ratio': Asset_To_Equity_Ratio,\n",
    "        'Capex to Cashflows': Capex_To_Cashflows,\n",
    "        'Downside Volatility': Downside_Volatility,\n",
    "        'EBIT to Assets': EBIT_To_Assets,\n",
    "        'EBITDA Yield': EBITDA_Yield,        \n",
    "        #'Earnings Quality': Earnings_Quality,\n",
    "        'CCI': CCI,\n",
    "        'Marketcap' : Market_Cap,\n",
    "        'MACD Signal Line': MACD_Signal_10d,\n",
    "        'Mean Reversion 1M': Mean_Reversion_1M,\n",
    "        'Moneyflow Volume 5D': Moneyflow_Volume_5d,\n",
    "        'Net Income Margin': Net_Income_Margin,        \n",
    "        'Operating Cashflows to Assets': Operating_Cashflows_To_Assets,\n",
    "        'Price Momentum 3M': Price_Momentum_3M,\n",
    "        'Price Oscillator': Price_Oscillator,\n",
    "        'Return on Invest Capital': Return_On_Total_Invest_Capital,\n",
    "        '39 Week Returns': Returns_39W,\n",
    "        'Trendline': Trendline,\n",
    "        'Vol 3M': Vol_3M,\n",
    "        'Working Capital to Assets': Working_Capital_To_Assets,\n",
    "        'Money Flow Index' : MFI\n",
    "    }        \n",
    "    \n",
    "    return all_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define universe and select factors to use\n",
    "We will screen our universe using the new [Q1500US](https://www.quantopian.com/posts/the-q500us-and-q1500us) and hand-pick a few alphas from the list above. We encourage you to play around with the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = Q1500US()\n",
    "\n",
    "factors = make_factors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and build the pipeline\n",
    "Next we have to build the pipeline. In addition to the factors defined above, we need the forward returns we want to predict. In this Notebook we will predict 5-day returns and train our model on daily data. You can also subsample the data to e.g. weekly to not have overlapping return periods but we omit this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fwd_days = 10 # number of days to compute returns over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_history_pipeline(factors, universe, n_fwd_days=5):\n",
    "    # Call .rank() on all factors and mask out the universe\n",
    "    factor_ranks = {name: f().rank(mask=universe) for name, f in factors.items()}\n",
    "    # Get cumulative returns over last n_fwd_days days. We will later shift these.\n",
    "    factor_ranks['CCI EMA 10-day'] = EWMA.from_span(inputs=[factor_ranks['CCI']],window_length=10,span=15)\n",
    "    factor_ranks['CCI EMA 20-day'] = EWMA.from_span(inputs=[factor_ranks['CCI']],window_length=20,span=15)\n",
    "\n",
    "    factor_ranks['Returns'] = Returns(inputs=[USEquityPricing.close],\n",
    "                                      mask=universe, window_length=n_fwd_days)\n",
    "    \n",
    "    factor_ranks['RSI 7-Day'] = RSI(inputs=[USEquityPricing.close], window_length=7)\n",
    "    \n",
    "    factor_ranks['RSI 14-Day'] = RSI(inputs=[USEquityPricing.close], window_length=14)\n",
    "    \n",
    "    factor_ranks['VWAP 10-Day'] = VWAP(window_length=10)\n",
    "    \n",
    "    factor_ranks['VWAP 30-Day'] = VWAP(window_length=30)\n",
    "    factor_ranks['Turnover 5d'] = SimpleMovingAverage(inputs=[USEquityPricing.volume], window_length=5) / v.shares_outstanding\n",
    "    factor_ranks['Turnover 10d'] = SimpleMovingAverage(inputs=[USEquityPricing.volume], window_length=10) / v.shares_outstanding\n",
    "    factor_ranks['Turnover 20d'] = SimpleMovingAverage(inputs=[USEquityPricing.volume], window_length=20) / v.shares_outstanding\n",
    "    factor_ranks['Turnover 120d'] = SimpleMovingAverage(inputs=[USEquityPricing.volume], window_length=120) / v.shares_outstanding\n",
    "    factor_ranks['Turnover 240d'] = SimpleMovingAverage(inputs=[USEquityPricing.volume], window_length=240) / v.shares_outstanding \n",
    "    \n",
    "    pipe = Pipeline(screen=universe, columns=factor_ranks)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_pipe = make_history_pipeline(factors, universe, n_fwd_days=n_fwd_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timer = time()\n",
    "start = pd.Timestamp(\"2020-06-01\")\n",
    "end = pd.Timestamp(\"2020-09-04\")\n",
    "results = run_pipeline(history_pipe, start_date=start, end_date=end)\n",
    "results.index.names = ['date', 'security']\n",
    "end_timer = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Time to run pipeline %.2f secs\" % (end_timer - start_timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Future Returns\"] = results.groupby(level=1)['Returns'].shift(-n_fwd_days)\n",
    "results.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results.index.get_level_values(1).map(lambda x: x.symbol == 'AAPL')]['Returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['new column name'] = df['column name'].apply(lambda x: 'value if condition is met' if x condition else 'value if condition is not met')\n",
    "results['Prediction'] = results[\"Future Returns\"].apply(lambda x: 1 if x > 0.02 else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to remove all rows that have an NaN value\n",
    "print('Before NaN drop we have {} rows and {} columns'.format(results.shape[0], results.shape[1]))\n",
    "\n",
    "# Any row that has a 'NaN' value will be dropped\n",
    "results = results.dropna()\n",
    "\n",
    "# Display how much is left after the removal\n",
    "print('After NaN drop we have {} rows and {} columns'.format(results.shape[0], results.shape[1]))\n",
    "\n",
    "# Print the head\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = results.drop(['Future Returns', 'Returns', 'Prediction'], axis=1)\n",
    "y = results['Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a seed so that the results are reproducible\n",
    "np.random.seed(415)\n",
    "\n",
    "#create and train model\n",
    "model = ensemble.RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Results'] = predictions\n",
    "last_day = X_test.index.get_level_values(level=0).max()\n",
    "last_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_predicted = X_test.query('(date==@last_day) and (Results == 1)')\n",
    "#stocks_predicted_upwards = predicted_upwards.index.get_level_values(level=1)\n",
    "positive_test = pd.concat([results, positive_predicted], axis=1)\n",
    "true_positive_test = positive_test.query('(date==@last_day) and (Returns >= 0.02) and (Results == 1)')['Returns']\n",
    "false_positive_test = positive_test.query('(date==@last_day) and (Returns < 0.02) and (Results == 1)')['Returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_positive_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(false_positive_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_test, predictions), \n",
    "    columns=['true:Downtrend', 'true:UpTrend'], \n",
    "    index=['predicted:Downtrend', 'predicted:UpTrend']\n",
    ")\n",
    "\n",
    "cmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_true = y_test, y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = model.predict_proba(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate y_score from the predicted probabilities of the positive (spy plane) class. \n",
    "y_score = model.predict_proba(X_test)[:,1]\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulate false positive rate, true positive rate, and threshold\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true = y_test, y_score = y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the roc_auc area\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the AUC-ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision\n",
    "metrics.precision_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate recall\n",
    "metrics.recall_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate F1 score\n",
    "metrics.f1_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lists of the features (column names) and the feature importances returned from our model\n",
    "features = X.columns\n",
    "importances = list(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the names and importances and sort\n",
    "feature_importance = list(zip(features, np.round(importances,2)))\n",
    "feature_importance.sort(key=lambda x:x[1], reverse = True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the feature importances\n",
    "features_ranked = list(zip(*feature_importance))[0]\n",
    "feat_imp_ranked = list(zip(*feature_importance))[1]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(features_ranked)]\n",
    "\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.xlabel('Analysis', fontsize = 18)\n",
    "plt.ylabel('Feature Importance', fontsize = 18)\n",
    "plt.bar(x_pos, feat_imp_ranked);\n",
    "\n",
    "plt.xticks(fontsize = 14, rotation=75)\n",
    "plt.xticks(x_pos, features_ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 3000, num = 200)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn import grid_search\n",
    "np.random.seed(415)\n",
    "model = ensemble.RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "model_rgs = grid_search.RandomizedSearchCV(estimator = model, param_distributions = random_grid, scoring = 'accuracy',\n",
    "                               n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "model_rgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at randomized search best parameters\n",
    "model_rgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model based on the hyperparameters from the above grid search\n",
    "np.random.seed(415)\n",
    "model_tuned = ensemble.RandomForestClassifier(n_estimators=1603, max_depth=10, max_features='auto', \n",
    "                               min_samples_leaf=2, min_samples_split=5, bootstrap=True)\n",
    "model_tuned.fit(X_train, y_train)\n",
    "\n",
    "predictions_tuned = model_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "precision_rgs = metrics.precision_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "recall_rgs = metrics.recall_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "accuracy_rgs = metrics.accuracy_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "print('Randomized Grid Search Metrics: Precision: ' + str(precision_rgs) + ' Recall: ' + str(recall_rgs) + \n",
    "      ' Accuracy: ' + str(accuracy_rgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lists of the features (column names) and the feature importances returned from our model\n",
    "features = X.columns\n",
    "importances = list(model_tuned.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the names and importances and sort\n",
    "feature_importance = list(zip(features, np.round(importances,2)))\n",
    "feature_importance.sort(key=lambda x:x[1], reverse = True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the feature importances\n",
    "features_ranked = list(zip(*feature_importance))[0]\n",
    "feat_imp_ranked = list(zip(*feature_importance))[1]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(features_ranked)]\n",
    "\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.xlabel('Analysis', fontsize = 18)\n",
    "plt.ylabel('Feature Importance', fontsize = 18)\n",
    "plt.bar(x_pos, feat_imp_ranked);\n",
    "\n",
    "plt.xticks(fontsize = 14, rotation=75)\n",
    "plt.xticks(x_pos, features_ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulate false positive rate, true positive rate, and threshold\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true = y_test, y_score = y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the roc_auc area\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the AUC-ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Machine Learning in a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestPredict(CustomFactor):\n",
    "        init = False\n",
    "\n",
    "    def compute(self, today, assets, out, returns, *inputs):\n",
    "        # inputs is a list of factors, for example, assume we have 2 alpha signals, 3 stocks,\n",
    "        # and a lookback of 2 days. Each element in the inputs list will be data of\n",
    "        # one signal, so len(inputs) == 2. Then each element will contain a 2-D array\n",
    "        # of shape [time x stocks]. For example:\n",
    "        # inputs[0]:\n",
    "        # [[1, 3, 2], # factor 1 rankings of day t-1 for 3 stocks  \n",
    "        #  [3, 2, 1]] # factor 1 rankings of day t for 3 stocks\n",
    "        # inputs[1]:\n",
    "        # [[2, 3, 1], # factor 2 rankings of day t-1 for 3 stocks\n",
    "        #  [1, 2, 3]] # factor 2 rankings of day t for 3 stocks\n",
    "        \n",
    "        if (not self.init) or (today.weekday() == 0): # Monday\n",
    "            model = ensemble.RandomForestClassifier()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Stack factor rankings\n",
    "            X = np.dstack(inputs) # (time, stocks, factors)\n",
    "            Y = returns # (time, stocks)\n",
    "            \n",
    "            out[:] = model.predict(X_test)[:, 1]\n",
    "            \n",
    "        \n",
    "            # Shift data to match with future returns and binarize \n",
    "            # returns based on their \n",
    "            X, Y = shift_mask_data(X, Y, n_fwd_days=n_fwd_days)\n",
    "            \n",
    "            X = self.imputer.fit_transform(X)            \n",
    "            X = self.scaler.fit_transform(X)\n",
    "            \n",
    "            # Fit the classifier\n",
    "            self.clf.fit(X, Y)\n",
    "            \n",
    "            self.init = True\n",
    "\n",
    "        # Predict\n",
    "        # Get most recent factor values (inputs always has the full history)\n",
    "        last_factor_values = get_last_values(inputs)\n",
    "        last_factor_values = self.imputer.transform(last_factor_values)\n",
    "        last_factor_values = self.scaler.transform(last_factor_values)\n",
    "\n",
    "        # Predict the probability for each stock going up \n",
    "        # (column 2 of the output of .predict_proba()) and\n",
    "        # return it via assignment to out.\n",
    "        out[:] = self.clf.predict_proba(last_factor_values)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(n_forward_days=10):\n",
    "    universe = Q1500US()\n",
    "    factors = make_factors()\n",
    "    \n",
    "    # Call .rank() on all factors and mask out the universe\n",
    "    factor_ranks = {name: f().rank(mask=universe) for name, f in factors.items()}\n",
    "    # Get cumulative returns over last n_fwd_days days. We will later shift these.\n",
    "    factor_ranks['Returns'] = Returns(inputs=[USEquityPricing.close],\n",
    "                                      mask=universe, window_length=n_fwd_days)\n",
    "    \n",
    "    factor_ranks['RSI 7-Day'] = RSI(inputs=[USEquityPricing.close], window_length=7) \n",
    "    factor_ranks['RSI 14-Day'] = RSI(inputs=[USEquityPricing.close], window_length=14)    \n",
    "    factor_ranks['VWAP 10-Day'] = VWAP(window_length=10) \n",
    "    factor_ranks['VWAP 30-Day'] = VWAP(window_length=30)\n",
    "    \n",
    "    return Pipeline(screen=universe, columns=factor_ranks)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "04a57a6a5ce417c7d7444ff7367eb1242e96002517d99bd63096a207043e57c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
