{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trending Value Analysis: The Best from Growth and Value\n",
    "\n",
    "By Joshua Genao\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we will analyze the Trending Value Portfolio that is mentioned in the Fourth edition of \"What Works On Wall Street\" by James O'Shaugnessy. In the \"Uniting The Best From Growth and Value\" chapter, O'Shaugnessy looks at uniting the best growth and value factors to produce a portfolio that is known as the Trending Value.\n",
    "\n",
    "We will be looking at the Value Composite Two which is composed of ranking the following factors:\n",
    "<ol>\n",
    "    <li>Price-to-book</li>\n",
    "    <li>Price-to-earnings</li>\n",
    "    <li>Price-to-sales</li>\n",
    "    <li>EBITDA/EV</li>\n",
    "    <li>Price-to-cash flow</li>\n",
    "    <li>Shareholder yield</li>\n",
    "</ol>\n",
    "\n",
    "We assign a percentile ranking (from 1 to 100) for each stock in the All Stock Universe. The book mentions that the All Stock Universe comprises of any stock with a market capitalization above $200 million.\n",
    "\n",
    "Stocks included in the Trending Value strategy must:\n",
    "<ol>\n",
    "    <li>Be a member of the All Stock Universe</li>\n",
    "    <li>Be in decile 1 of the composited Value Factor Two (10% of the best stocks with best valuation scores across all 6 factors)</li>\n",
    "    <li>Buy the 25 stocks with the best 6-month price appreciation</li>\n",
    "</ol>\n",
    "\n",
    "The portfolio is rebalanced every year.\n",
    "\n",
    "Note: James O'Shaughnessy is using Compustat data ranging from 1964 to 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending Value Portfolio\n",
    "Lets first construct the portfolio by ranking all the value factors above from the All Stock Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.pipeline import Pipeline, CustomFilter\n",
    "from quantopian.pipeline.factors import CustomFactor\n",
    "from quantopian.pipeline.data import Fundamentals\n",
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantiles class was created in order to change any results that contains a NaN value into a neutral rank of 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ebitda_to_EV(CustomFactor):\n",
    "    '''\n",
    "    The book uses EBITDA/EV. Fundamental data gives us access to EV/EBITDA. \n",
    "    EBITDA/EV = 1/(EV/EBITDA)\n",
    "    If result gives us an infinite number, that is changed to NaN. This will \n",
    "    be handled when passing it to the Quantiles function\n",
    "    '''\n",
    "    window_length = 1\n",
    "    inputs=[Fundamentals.ev_to_ebitda]\n",
    "    \n",
    "    def compute(self, today, assets, out, ev_ebitda):\n",
    "        result = 1 / ev_ebitda[-1]\n",
    "        result[np.isinf(result)] = np.nan\n",
    "        out[:] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum(CustomFactor):\n",
    "    '''\n",
    "    Momentum is calculated by determining the price appreciation.\n",
    "    Price appreciation = current price - previous price / previous price\n",
    "    This will gives us a decimal value.\n",
    "    '''\n",
    "    inputs=[USEquityPricing.open]\n",
    "    def compute(self, today, assets, out, price):\n",
    "        out[:] = (price[-1] - price[0]) / price[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantiles(CustomFactor):\n",
    "    window_length = 1\n",
    "    params = ('q_type', 'q_value',)\n",
    "    fill_value = 50 \n",
    "    \n",
    "    def compute(self, today, assets, out, factor, q_type, q_value):\n",
    "        try:\n",
    "            if q_type == 'quantiles':\n",
    "                result = pd.qcut(factor, q_value, labels=False) + 1   \n",
    "            elif q_type == 'bins':\n",
    "                result = pd.cut(factor, q_value, labels=False) + 1\n",
    "            else:\n",
    "                raise ValueError('Either quantiles or bins should be provided')\n",
    "            \n",
    "            result[np.isinf(result)] = self.fill_value\n",
    "            result[np.isnan(result)] = self.fill_value\n",
    "            out[:] = result  \n",
    "        except:\n",
    "            out[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    # All Stocks universe consist of stocks with a market capitalization in excess of $200 mil\n",
    "    all_stock_universe = Fundamentals.market_cap.latest > 200000000\n",
    "    \n",
    "    # Get the latest of all factors from the Value Composite 2\n",
    "    '''\n",
    "    pb_ratio = Fundamentals.pb_ratio.latest\n",
    "    pe_ratio = Fundamentals.pe_ratio.latest\n",
    "    ps_ratio = Fundamentals.ps_ratio.latest\n",
    "    ebitda_ev = Ebitda_to_EV()\n",
    "    price_to_cashflow = Fundamentals.pcf_ratio.latest\n",
    "    shareholder_yield = Fundamentals.total_yield.latest\n",
    "    '''\n",
    "    #ebitda_ev = Ebitda_to_EV()\n",
    "\n",
    "    \n",
    "    # Factors that receives a rank of 100 in the lowest 1 percent of the universe and\n",
    "    # a rank of 1 in the highest 1 percent of the universe\n",
    "    '''\n",
    "    pb_ratio_rank = pb_ratio.rank(ascending=False, mask=all_stock_universe)\n",
    "    pe_ratio_rank = pe_ratio.rank(ascending=False, mask=all_stock_universe)\n",
    "    ps_ratio_rank = ps_ratio.rank(ascending=False, mask=all_stock_universe)\n",
    "    price_to_cashflow_rank = price_to_cashflow.rank(ascending=False, mask=all_stock_universe)\n",
    "    '''\n",
    "    \n",
    "    # Factors that receives a rank of 100 in the highest 1 percent of the universe and\n",
    "    # a rank of 1 in the lowest 1 percent of the universe\n",
    "    cash_return = Fundamentals.cash_return.latest.rank(mask=all_stock_universe)\n",
    "    fcf_yield = Fundamentals.fcf_yield.latest.rank(mask=all_stock_universe)\n",
    "    roic = Fundamentals.roic.latest.rank(mask=all_stock_universe)\n",
    "    ltd_to_eq = Fundamentals.long_term_debt_equity_ratio.latest.rank(mask=all_stock_universe)\n",
    "    \n",
    "    #shareholder_yield_rank = shareholder_yield.rank(mask=all_stock_universe)\n",
    "    #ebitda_ev_rank = ebitda_ev.rank(mask=all_stock_universe)\n",
    "    \n",
    "    cash_return_quantiles = Quantiles(inputs=[cash_return], q_type='quantiles', q_value=100)\n",
    "    fcf_yield_quantiles = Quantiles(inputs=[fcf_yield], q_type='quantiles', q_value=100)\n",
    "    roic_quantiles = Quantiles(inputs=[roic], q_type='quantiles', q_value=100)\n",
    "    ltd_to_eq_quantile = Quantiles(inputs=[ltd_to_eq], q_type='quantiles', q_value=100)\n",
    "    #pb_ratio_quantiles = Quantiles(inputs=[pb_ratio_rank], q_type='quantiles', q_value=100)\n",
    "    #pe_ratio_quantiles = Quantiles(inputs=[pe_ratio_rank], q_type='quantiles', q_value=100) \n",
    "    #ps_ratio_quantiles = Quantiles(inputs=[ps_ratio_rank], q_type='quantiles', q_value=100)\n",
    "    #ebitda_ev_rank_quantiles = Quantiles(inputs=[ebitda_ev_rank], q_type='quantiles', q_value=100)\n",
    "    #price_to_cashflow_quantiles = Quantiles(inputs=[price_to_cashflow_rank], q_type='quantiles', q_value=100)\n",
    "    #shareholder_yield_quantiles = Quantiles(inputs=[shareholder_yield_rank], q_type='quantiles', q_value=100)\n",
    "    \n",
    "    \n",
    "    #score = pb_ratio_quantiles + pe_ratio_quantiles + ps_ratio_quantiles + ebitda_ev_rank_quantiles + price_to_cashflow_quantiles + shareholder_yield_quantiles\n",
    "    #score_rank = score.rank(ascending=False)\n",
    "    score = ( cash_return_quantiles + fcf_yield_quantiles + ltd_to_eq_quantile + roic_quantiles ).rank(ascending=False)\n",
    "    #score_decile = Quantiles(inputs=[score_rank], q_type='quantiles', q_value=10)\n",
    "    \n",
    "    top_quality = score.top(100, mask=all_stock_universe)\n",
    "    #momentum_6mon = Momentum(window_length = 180, mask=all_stock_universe)\n",
    "    #momentum_rank = momentum_6mon.rank(ascending=False, mask=score_decile.eq(1))\n",
    "    momentum = Momentum(window_length = 180, mask=top_quality)\n",
    "    # assign a percentile ranking (from 1 to 100)\n",
    "    # e.g if a stock has PE ratio that is in the lowest 1 percent it receives a rank of 100\n",
    "    \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            'factor' : momentum\n",
    "        },\n",
    "        screen=top_quality\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets determine if the data seems correct. The following factors should have a rank of 100 if it is in the lowest 1 percent of the universe:\n",
    "<ul>\n",
    "    <li>Price-to-book</li>\n",
    "    <li>Price-to-earnings</li>\n",
    "    <li>Price-to-sales</li>\n",
    "    <li>Price-to-cashflow</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import run_pipeline method\n",
    "from quantopian.research import run_pipeline\n",
    "\n",
    "# Specify a time range to evaluate\n",
    "period_start = '2010-01-01'\n",
    "period_end = '2019-01-01'\n",
    "\n",
    "# Execute pipeline over evaluation period\n",
    "pipeline_output = run_pipeline(\n",
    "    make_pipeline(),\n",
    "    start_date=period_start,\n",
    "    end_date=period_end\n",
    ")\n",
    "\n",
    "print \"There are %d assets in this universe.\" % len(pipeline_output.index.levels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Value Factor Two\n",
    "Lets determine how well the Value Factor Two portfolio does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphalens\n",
    "\n",
    "#Gets each unique stock ticker and puts it in assets\n",
    "assets = pipeline_output.index.levels[1].unique()\n",
    "\n",
    "#gets pricing data. Needs a month before and after. Dunno why.\n",
    "pricing = get_pricing(assets, start_date='2010-01-01', end_date='2019-01-01', fields='open_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest and format data\n",
    "factor_data = alphalens.utils.get_clean_factor_and_forward_returns(pipeline_output,\n",
    "                                                                   pricing,\n",
    "                                                                   periods=(30,60,90),\n",
    "                                                                   quantiles=10\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.tears.create_information_tear_sheet(factor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_return_by_q, std_err_by_q = alphalens.performance.mean_return_by_quantile(factor_data,\n",
    "                                                                               by_group=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_return_by_q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.plotting.plot_quantile_returns_bar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalens.tears.create_returns_tear_sheet(factor_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "04a57a6a5ce417c7d7444ff7367eb1242e96002517d99bd63096a207043e57c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
